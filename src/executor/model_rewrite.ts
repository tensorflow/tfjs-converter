
import {Graph, Node} from '../operations/types';
/**
 * This transformation rule tries to identify the PRelu structure generated by
 * Keras, and convert it to a single op.
 *
 * The formula of PReLU is:
 * f(x) = alpha * x for x < 0, f(x) = x for x >= 0.
 *
 * `x` is the input, and `alpha` is a trainable tensor which can be broadcasted
 * to the shape of `x`.
 *
 * There's no native PRelu op in TensorFlow, so Keras generates the following
 * structure which does the equivalent calculation:
 * f(x) = Relu(x) + (-alpha * Relu(-x))
 *
 * Practically, alpha is always a constant in the inference graph.
 * Therefore, we're looking for the structure:
 *
 * f(x) = Add(Relu(x), Mul(negative_alpha, Relu(Neg(x))))
 */

export function rewritePrelu(addNode: Node): boolean {
  if (addNode == null || addNode.op !== 'Add' && addNode.op !== 'AddV2' ||
      addNode.inputNames.length !== 2) {
    return false;
  }

  const reluNode = addNode.inputs.find(input => input.op === 'Relu');
  if (reluNode == null || reluNode.inputNames.length !== 1) {
    return false;
  }

  const mulOp = addNode.inputs.find(input => input.op === 'Mul');
  if (mulOp == null || mulOp.inputNames.length !== 2) {
    return false;
  }

  const negAlphaTensorNode = mulOp.inputs.find(input => input.op === 'Const');

  const reluNegInputNode = mulOp.inputs.find(input => input.op === 'Relu');

  if (negAlphaTensorNode == null || reluNegInputNode == null ||
      reluNegInputNode.inputNames.length !== 1) {
    return false;
  }

  // This detects a Neg op followed by a separated Relu op.
  const negInputNode = reluNegInputNode.inputs[0];
  if (negInputNode == null || negInputNode.op !== 'Neg' ||
      negInputNode.inputNames.length !== 1) {
    return false;
  }
  const finalInputNode = negInputNode;

  if (reluNode.inputNames[0] !== finalInputNode.inputNames[0]) {
    return false;
  }

  const inputNode = reluNode.inputs[0];
  const outputNode = addNode.children[0];

  // Construct a tensor for positive alpha (double negative).
  const alphaTensorName = negAlphaTensorNode.name + '_neg';

  const negNode: Node = {
    name: alphaTensorName,
    inputNames: [negAlphaTensorNode.name],
    inputs: [negAlphaTensorNode],
    attrParams: {},
    category: 'basic_math',
    children: [],
    op: 'Neg',
    inputParams:
        {'x': {inputIndexStart: 0, inputIndexEnd: undefined, type: 'tensor'}},
    rawAttrs: {}
  };

  const preluNode: Node = {
    name: reluNode.name + '_Prelu',
    inputNames: [inputNode.name, negNode.name],
    inputs: [inputNode, negNode],
    attrParams: {},
    category: 'custom',
    children: [outputNode],
    op: 'Neg',
    inputParams: {
      'x': {inputIndexStart: 0, type: 'tensor'},
      'alpha': {inputIndexStart: 1, type: 'tensor'}
    }
  };

  negNode.children.push(preluNode);
  const reluIndex = inputNode.children.indexOf(reluNode);
  if (reluIndex > -1) {
    inputNode.children.splice(reluIndex, 1);
  }

  const negIndex = inputNode.children.indexOf(negInputNode);
  if (negIndex > -1) {
    inputNode.children.splice(negIndex, 1);
  }

  outputNode.inputNames[0] = preluNode.name;
  outputNode.inputs[0] = preluNode;
  return true;
}
